{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efd9e210-72d8-4436-9a27-7c3243699867",
   "metadata": {},
   "source": [
    "# Teste do modelo treinado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006fee38-630f-4548-b749-182afdeda016",
   "metadata": {},
   "source": [
    "[Voltar ao Índice](../00_indice.ipynb)\n",
    "\n",
    "Aqui carregamos o modelo BERT de detecção de discursos violentos, previamente treinado e salvo, e o aplicamos a casos de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7427d2a-85bf-4c35-87ea-5bf645e3c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speechwrapper as sw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from xavy.mltools import shuffled_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f90bd60-4f3b-46d8-acc2-d357dd3feabb",
   "metadata": {},
   "source": [
    "#### Carrega o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dfa6b67-3a02-4e1f-abb7-71782b3499b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer from neuralmind/bert-base-portuguese-cased\n",
      "Loading trained model: ../modelos/bertimbau-hatespeech-v01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-08 22:02:15.111323: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-08-08 22:02:15.111364: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: glitterbu\n",
      "2022-08-08 22:02:15.111371: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: glitterbu\n",
      "2022-08-08 22:02:15.111511: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 390.154.0\n",
      "2022-08-08 22:02:15.111537: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 390.154.0\n",
      "2022-08-08 22:02:15.111543: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 390.154.0\n",
      "2022-08-08 22:02:15.131734: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-08 22:02:15.733976: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 91527168 exceeds 10% of free system memory.\n",
      "2022-08-08 22:02:15.907726: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 91527168 exceeds 10% of free system memory.\n",
      "2022-08-08 22:02:15.956094: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 91527168 exceeds 10% of free system memory.\n",
      "2022-08-08 22:02:22.998780: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 91527168 exceeds 10% of free system memory.\n",
      "2022-08-08 22:02:23.055746: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 91527168 exceeds 10% of free system memory.\n",
      "Some layers from the model checkpoint at ../modelos/bertimbau-hatespeech-v01 were not used when initializing TFBertForSequenceClassification: ['dropout_151']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at ../modelos/bertimbau-hatespeech-v01.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = sw.HateSpeechModel('../../modelos/bertimbau-hatespeech-v01')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a341212e-279d-4fbe-b939-2de89df4c115",
   "metadata": {},
   "source": [
    "#### Carrega os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73dd4355-3840-4f7a-809c-877b0e100c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../../dados/processados/hatespeech_fortuna3+offcombr2_test_seed1323.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558b4827-2d49-4adf-bf38-7ab187fc0b7e",
   "metadata": {},
   "source": [
    "#### Prediz com o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "415cf608-4b91-4b4b-9e77-2f2a6d4f451b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.00s/ba]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 121s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Valores verdadeiros:\n",
    "y_test = test_df['label']\n",
    "# Prediz a classe:\n",
    "y_test_pred = model.predict_class(test_df['text'])\n",
    "# Calcula a probabilidade:\n",
    "y_test_prob = model.predict_proba(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "276c6cd7-8d85-4cfb-84ef-90a0b5aa32bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.903\n",
      "f1: 0.602\n",
      "prec: 0.705\n",
      "rec: 0.525\n"
     ]
    }
   ],
   "source": [
    "# Metrics:\n",
    "for name, scorer in {'acc': accuracy_score, 'f1': f1_score, 'prec': precision_score, 'rec': recall_score}.items():\n",
    "    s = scorer(y_test, y_test_pred)\n",
    "    print('{}: {:.3f}'.format(name, s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291525c-99db-43e3-bbdb-9dafba59785e",
   "metadata": {},
   "source": [
    "#### Teste de cálculo de número de agressões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6f555112-982a-4d72-b89f-e6086a1a9bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_split   = 5\n",
    "n_samples = len(y_test)\n",
    "batch_size = int(n_samples / n_split)\n",
    "\n",
    "n_true = []\n",
    "n_est  = []\n",
    "n_pred = []\n",
    "shuffler = shuffled_pos(len(y_test), 1)\n",
    "for i in range(n_split):\n",
    "    y_true_batch = y_test[shuffler][batch_size * i: batch_size * (i + 1)]\n",
    "    y_prob_batch = y_test_prob[shuffler][batch_size * i: batch_size * (i + 1)]\n",
    "    y_pred_batch = y_test_pred[shuffler][batch_size * i: batch_size * (i + 1)]\n",
    "    n_true.append(y_true_batch.sum())\n",
    "    n_est.append(y_prob_batch.sum())\n",
    "    n_pred.append(y_pred_batch.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6c9a58-bdc7-4e80-a449-7673e7399479",
   "metadata": {},
   "source": [
    "Por soma das probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "754261db-a5c2-4aa5-b82c-f3347e942422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias:  0.3576\n",
      "StDev: 1.4311\n"
     ]
    }
   ],
   "source": [
    "print('Bias:  {:.4f}'.format(np.mean(np.array(n_est) - np.array(n_true))))\n",
    "print('StDev: {:.4f}'.format(np.std(np.array(n_est) - np.array(n_true))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36a3b5d-a5df-412f-934b-3be094a3232d",
   "metadata": {},
   "source": [
    "Por soma das predições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f74e0cb6-9389-4444-8fd9-aaed7557a75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias:  -5.8000\n",
      "StDev: 1.6000\n"
     ]
    }
   ],
   "source": [
    "print('Bias:  {:.4f}'.format(np.mean(np.array(n_pred) - np.array(n_true))))\n",
    "print('StDev: {:.4f}'.format(np.std(np.array(n_pred) - np.array(n_true))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3330f4e0-8895-4ef1-bb6b-74927676946e",
   "metadata": {},
   "source": [
    "# Lixo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e174fdbc-4072-4274-be58-784f1799f074",
   "metadata": {},
   "source": [
    "## Módulo externo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea190fe-d63e-4182-8fbc-fe8324177522",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c55d055-af03-4722-8217-ef5ec9a54c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_texts = ['Essa aí e tão piranha que eu nem pegava.',\n",
    "             'Bolsonarista só se resolve na base da porrada.',\n",
    "             'Esquerdista só se resolve na base da porrada.',\n",
    "             'Seu preto sujo nojento',\n",
    "             'Só podia ser preto favelado mesmo',\n",
    "             'Seu liberal safado, você vai ver.',\n",
    "             'MST é tudo terrorista',\n",
    "             'Vai sua bicha',\n",
    "             'Essa aí é sapatão',\n",
    "             'Você é um palhaço mesmo! kkkkk',\n",
    "             'Miga, você é muito escrota',\n",
    "             'Estarei te esperando com minha glock, pode chegar',\n",
    "             'Você vai adorar a pica que eu vou botar',\n",
    "             'Esses bolivianos ignorantes vem encher o saco',\n",
    "             'Vocês deviam voltar pra áfrica',\n",
    "             'Lugar de mulher é na cozinha',\n",
    "             'Você é bandido, e bandido bom é bandido morto!',\n",
    "             'ceh bandido badido bom e bandido morto',\n",
    "             'Empresta seu cabelo pra eu ariar uma panela',\n",
    "             'Macaco',\n",
    "             'macaco',\n",
    "             'Tá com fome, eu te dou uma banana kkkkk',\n",
    "             'condizente com o cérebro de quem apóia ladrões!! Não se pode esperar muito…']\n",
    "\n",
    "good_texts = ['Piranha é o nome de um peixe',\n",
    "              'Bolsonarista não respeita a democracia',\n",
    "              'Esquerdista não respeita a democracia',\n",
    "              'O lençol é sujo e nojento',\n",
    "              'A polícia só mata preto e favelado',\n",
    "              'Ele é o liberal mais safado que eu conheço.',\n",
    "              'Al Quaeda são terroristas',\n",
    "              'A bichinha miou tanto que deu uma dó!',\n",
    "              'E aquele sapatão do palhaço?',\n",
    "              'Tinha uns palhaços muito engraçados no circo ontem.',\n",
    "              'Boa miga! Tamo junto',\n",
    "              'To te esperando com um cafezinho, pode chegar',\n",
    "              'Você vai adorar a grana que eu vou botar',\n",
    "              'Fico com muita dor quando uma abelha me pica',\n",
    "              'Os bolivianos viajam com um saco ao invês de mochila',\n",
    "              'Vamos voltar à áfrica',\n",
    "              'Lugar de mulher é onde ela quiser',\n",
    "              'Não gostei nada da sua última proposta, com exceção, talvez, da parte 2.',\n",
    "              'n gostei da sua proposta com ecessao da parte 2.',\n",
    "              'dizem que há corrupção no governo Bolsonaro',\n",
    "              'diz q a corupcao no gov bolsonaro',\n",
    "              'Mas esse bombril é tão ruim que não dá nem pra ariar panela',\n",
    "              'Cada macaco no seu galho',\n",
    "              'Com o preço da banana eu tô é com fome',\n",
    "              'Bola para frente tudo tem seu tempo e a Hora vai chegar',\n",
    "              'Para de firulas vamos para a realidade, que está muito distante da sua existência!!',\n",
    "              'Votei em você e decepcionei. Te parabenizo por chegar tão longe. Mas p governador, me desculpe. O ES merece mais.']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddcb22e-0288-466b-8cfe-f0e9dd2c062f",
   "metadata": {},
   "source": [
    "## Prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "203ce8cb-c77d-4113-8133-f43bf91a874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xavy.dataframes as xd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "359e1549-1286-4f1d-9ad3-4c04cd1aa48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Hugging Face:\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from datasets import Dataset \n",
    "from transformers import DefaultDataCollator "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b22a90a-bfcf-4e3b-9ea2-eb619d315529",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffbfd89c-6a95-4e15-b411-8300f94a2318",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "### Splitting datasets into random sets ###\n",
    "###########################################\n",
    "\n",
    "def shuffled_pos(length, seed):\n",
    "    \"\"\"\n",
    "    Return indices from 0 to `length` - 1 in a shuffled state, given random `seed`.\n",
    "    \"\"\"\n",
    "    return np.random.RandomState(seed=seed).permutation(length)\n",
    "\n",
    "\n",
    "def random_index_sets(size, set_fracs, seed):\n",
    "    \"\"\"\n",
    "    Return sets of random indices (from 0 to `size` - 1) with lengths \n",
    "    given by ~ `size` * `set_fracs`.\n",
    "    \n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    \n",
    "    size : int\n",
    "        The size of the index list to split into sets.\n",
    "        \n",
    "    set_fracs : iterable\n",
    "        The fractions of the list of indices that each index set \n",
    "        should contain. \n",
    "    \n",
    "    seed : int\n",
    "        The seed for the random number generator.\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    indices : tuple of arrays\n",
    "        The indices for each set.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert np.isclose(np.sum(set_fracs), 1), '`set_fracs` should add up to one.'\n",
    "    \n",
    "    # Create randomized list of indices:\n",
    "    shuffled_indices = shuffled_pos(size, seed)\n",
    "    \n",
    "    \n",
    "    indices   = []\n",
    "    set_start = [0]\n",
    "    # Determine the sizes of the sets:\n",
    "    set_sizes = [round(size * f) for f in set_fracs]\n",
    "    set_sizes[0] = size - sum(set_sizes[1:])\n",
    "    assert np.sum(set_sizes) == size, 'Set sizes should add up to total size.'\n",
    "    \n",
    "    for i in range(0, len(set_fracs) - 1):\n",
    "        # Select indices for a set:\n",
    "        set_start.append(set_start[i] + set_sizes[i])\n",
    "        set_indices = shuffled_indices[set_start[i]:set_start[i + 1]]\n",
    "        indices.append(set_indices)\n",
    "        assert len(indices[i]) == len(set(indices[i])), 'There are repeating indices in a set.'\n",
    "        \n",
    "    # Select the indices for the last set:\n",
    "    indices.append(shuffled_indices[set_start[-1]:])\n",
    "    assert len(set(np.concatenate(indices))) == sum([len(i) for i in indices]), \\\n",
    "    'There are common indices between sets.'\n",
    "    \n",
    "    return tuple(indices)\n",
    "\n",
    "\n",
    "def random_set_split(df, set_fracs, seed):\n",
    "    \"\"\"\n",
    "    Split a DataFrame into randomly selected disjoint and complete sets.\n",
    "    \n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    \n",
    "    df : Pandas DataFrame\n",
    "        The dataframe to split into a complete and disjoint set of sub-sets.\n",
    "        \n",
    "    set_fracs : array-like\n",
    "        The fraction of `df` that should be put into each set. The length of \n",
    "        `set_fracs` determines the number of sub-sets to create.\n",
    "    \n",
    "    seed : int\n",
    "        The seed for the random number generator used to split `df`.\n",
    "        \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    A tuple of DataFrames, one for each fraction in `set_fracs`, in that order.\n",
    "    \"\"\"\n",
    "    # Get positional indices for each set:\n",
    "    sets_idx = random_index_sets(len(df), set_fracs, seed)\n",
    "    \n",
    "    return tuple(df.iloc[idx] for idx in sets_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "725dac4a-f2d6-4be2-952e-7e4ef101b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pandas_to_tfdataset(df, tokenizer, max_length=80, shuffle=True, text_col='text', target_col='label', batch_size=8):\n",
    "    \"\"\"\n",
    "    Prepare NLP data in a Pandas DataFrame to be used \n",
    "    in a TensorFlow transformer model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        The corpus, containing the columns `text_col` \n",
    "        (the sentences) and `target_col` (the labels).\n",
    "    tokenizer : HuggingFace AutoTokenizer\n",
    "        A tokenizer loaded from \n",
    "        `transformers.AutoTokenizer.from_pretrained()`.\n",
    "    max_length : int\n",
    "        Maximum length of the sentences (smaller \n",
    "        sentences will be padded and longer ones\n",
    "        will be truncated). This is required for \n",
    "        training, so batches have instances of the\n",
    "        same shape.\n",
    "    shuffle : bool\n",
    "        Shuffle the dataset order when loading. \n",
    "        Recommended True for training, False for \n",
    "        validation/evaluation.\n",
    "    text_col : str\n",
    "        Name of `df` column containing the sentences.\n",
    "    target_col : str\n",
    "        Name of `df` column containing the labels of \n",
    "        the sentences.\n",
    "    batch_size : int\n",
    "        The size of the batch in the output \n",
    "        tensorflow dataset.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tf_dataset : TF dataset\n",
    "        A dataset that can be fed into a transformer \n",
    "        model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Security checks:\n",
    "    renamed_df = df.rename({target_col:'labels'}, axis=1) # Hugging Face requer esse nome p/ y.\n",
    "    \n",
    "    # Define função para processar os dados com o tokenizador:\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[text_col], padding=True, max_length=max_length, truncation=True)\n",
    "    \n",
    "    # pandas -> hugging face:\n",
    "    hugging_set = Dataset.from_pandas(renamed_df)\n",
    "    # texto -> sequência de IDs: \n",
    "    encoded_set = hugging_set.map(tokenize_function, batched=True)\n",
    "    # hugging face -> tensorflow dataset:\n",
    "    data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "    tf_dataset = encoded_set.to_tf_dataset(columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"], label_cols=[\"labels\"], shuffle=shuffle, collate_fn=data_collator, batch_size=batch_size)\n",
    "    \n",
    "    return tf_dataset\n",
    "\n",
    "\n",
    "def predict_proba(model, tf_dataset):\n",
    "    \"\"\"\n",
    "    Use the provided model to compute the\n",
    "    probability that each instance is \n",
    "    in the positive class (1 in a binary \n",
    "    classification).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : TFBertForSequenceClassification\n",
    "        A Hugging Face implementation of a \n",
    "        Tensorflow transformer model.\n",
    "    tf_dataset : Tensorflow Dataset\n",
    "        The data for which to make predictions.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    probs : array\n",
    "        Probability that the corresponding \n",
    "        instance falls in the positive class\n",
    "        (y = 1).\n",
    "    \"\"\"\n",
    "\n",
    "    tf_predict = model.predict(tf_dataset).logits\n",
    "    probs = tf.sigmoid(tf_predict)[:,0].numpy()\n",
    "    \n",
    "    return probs\n",
    "\n",
    "\n",
    "def predict_class(model, tf_dataset, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Use the provided model to predict\n",
    "    the class of each instance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : TFBertForSequenceClassification\n",
    "        A Hugging Face implementation of a \n",
    "        Tensorflow transformer model.\n",
    "    tf_dataset : Tensorflow Dataset\n",
    "        The data for which to make predictions.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    preds : array\n",
    "        Predicted class for the corresponding\n",
    "        instances.\n",
    "    \"\"\"\n",
    "\n",
    "    probs = predict_proba(model, tf_dataset)\n",
    "    preds = (probs > threshold).astype(int)\n",
    "\n",
    "    return preds\n",
    "\n",
    "\n",
    "def rate_speech_for_hate(model, tokenizer, texts):\n",
    "    \"\"\"\n",
    "    Rate the level of violence in the sentences.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : TFAutoModelForSequenceClassification\n",
    "        Trained Hugging Face transformer model \n",
    "        for hate speech identification.\n",
    "    tokenizer : AutoTokenizer\n",
    "        Hugging Face tokenizer.\n",
    "    texts : str or list of str\n",
    "        Sentences to classify.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    probs : array\n",
    "        Probabilities that the sentences in \n",
    "        `texts` contain violence.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Standardize input:\n",
    "    if type(texts) == str:\n",
    "        texts = [texts]\n",
    "    \n",
    "    # Prepare date format and tokenize:\n",
    "    input_df  = pd.DataFrame({'text': texts, 'label': [1] * len(texts)})\n",
    "    input_tfd = process_pandas_to_tfdataset(input_df, tokenizer, shuffle=False)\n",
    "    # Predict with model:\n",
    "    probs = predict_proba(model, input_tfd)\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a4d1a-5f9c-424b-85db-236bcd70ca43",
   "metadata": {},
   "source": [
    "## Carregando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced2b9a0-28a8-4ad8-ab0e-38d37ddf3531",
   "metadata": {},
   "source": [
    "Fonte: Juntamos os dados de Fortuna e Pelle (veja o notebook do modelo baseline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5289138e-ee9e-4b56-aaff-339fa67e7a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega os dados:\n",
    "mass_df = pd.read_csv('../../dados/processados/hatespeech_fortuna3+offcombr2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95742d83-58c9-4e33-a717-46c94ab90801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa os dados em amostras:\n",
    "train_df, val_df, test_df = random_set_split(mass_df, [0.7, 0.15, 0.15], 1323)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40cf8eb-5936-487d-b63e-cc64d2f7b1ad",
   "metadata": {},
   "source": [
    "## Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07196fa-f707-41cd-8286-e163ce482ade",
   "metadata": {},
   "source": [
    "### Carrega o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83ff54ec-8f53-4dbc-aaa8-0cdf987cdc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../modelos/bertimbau-hatespeech-v01 were not used when initializing TFBertForSequenceClassification: ['dropout_151']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at ../modelos/bertimbau-hatespeech-v01.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Carrega tokenizer:\n",
    "tokenizer  = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=False)\n",
    "# Carrega o modelo:\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained('../../modelos/bertimbau-hatespeech-v01')\n",
    "#model2 = TFAutoModelForSequenceClassification.from_pretrained('../../modelos/bertimbau-hatespeech-v02')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c986114-0698-4979-96e5-38a9504f7649",
   "metadata": {},
   "source": [
    "### Testa nos dados rotulados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e56e0c9e-8799-471e-9ebe-5b7f1f3fab1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m0\u001b[0m: RT @DaniloGentili: Quando João Kleber faz na Rede TV=Putaria, Mau Gosto, Baixaria\n",
      "Quando fazem na Globo=Ousadia, Arte, Tapa na cada da soc _\n",
      "\u001b[1m0\u001b[0m: RT @Leandroow3: só pode comemorar quem viu o pai voltar com o cigarro\n",
      "\u001b[1m1\u001b[0m: @bbb17aovivo quero ver a cara do recauque quando a emili pegar o lider e joga a roberta no paredao aquela vaca fausa gorda e feia rsrrsrsrsr\n",
      "\u001b[1m0\u001b[0m: Volta a Copa 2014 ae só pra eu ver um negócio aqui rapidão\n",
      "\u001b[1m1\u001b[0m: @homemdeverdade pega forte na cintura da sua fêmea, essa coisa de delicadeza nessas horas é desses Jonnys Manés Citricos bunda mole!\n"
     ]
    }
   ],
   "source": [
    "sampled_df = test_df.sample(5)\n",
    "xd.print_string_series(sampled_df.set_index('label')['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d3aa02c0-881b-44fa-8c64-d27eb8d86fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 216.00ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 373ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.24199916, 0.02296981, 0.6980702 , 0.15228723, 0.92074054],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts = list(sampled_df['text'])\n",
    "rate_speech_for_hate(model, tokenizer, input_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425e8a5a-cf23-4df8-ba10-e76f9a55701d",
   "metadata": {},
   "source": [
    "### Testes com posts reais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1166016e-7110-474c-98ba-19c8edc2103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = ['@tabataamaralsp O Estado não pode ser responsável pelos pais que colocam filhos no mundo e não consegue dar o mínimo de “educação” o que é diferente de escolaridade.',\n",
    " '@tabataamaralsp Pra te apoiar tem que ser muito desinformada.\\nVocê, apesar de jovem, representa a velha política.\\nEspero que não seja reeleita.\\nVocê foi uma decepção.',\n",
    " '@tabataamaralsp Parabéns, estamos  juntos..',\n",
    " '@LulaOficial @gleisi @IvanValente @pauloteixeira13 @paulopaim @mariadorosario @tabataamaralsp @senadorhumberto O povo brasileiro, de bem, não esqueceu o tipo de governança do PT: Cleptocracia Estado governado por ladrões.\\n#PTNuncaMais https://t.co/TX5CC7zJKg',\n",
    " '📄 A deputada federal @tabataamaralsp encaminhou ofício ao Ministério da Cidadania pedindo mais transparência na divulgação de dados sobre a fila de espera do #AuxílioBrasil: https://t.co/FHQ3NPxIWq',\n",
    " '@tabataamaralsp boa tarde \"cumpanhêra\" https://t.co/5sspVpUSnn',\n",
    " '@tabataamaralsp ESTAMOS ESPERANDO UM POUCO DE LUCIDEZ SUA .',\n",
    " '@Tali_Mito22 @tabataamaralsp Essa é a rainha dos \"idiotas uteis\". Next 👉',\n",
    " '@tabataamaralsp Da serie fakenews e democratico https://t.co/HHMPyqo2zl',\n",
    " '@LucasSousaR @tabataamaralsp @Papaulo1337 @_luizmorais_ Exatamente! \\n\\nhttps://t.co/ZZfQlxjT6p']\n",
    "posts = ['ELA SO FALA EM CORRUPÇAO, MAS NO FUNDO E DA MESMA PANELA, E CAIU NOS BRAÇOS DO MAIOR CORRUPTO DESDE BRASIL, MESU PARABENS SUA IDIOTA PERFEITA, JA COMEÇE A ARRUMAR OUTRA COISA PARA FAZER, POIS O BRASIL VAI VOTAR EM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10498cf1-34a2-4c48-8bd3-9e0c42e19f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 355.24ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 201ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.54134405], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_speech_for_hate(model, tokenizer, posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c14c6cc-cdfd-46a6-a462-e76621dae6a5",
   "metadata": {},
   "source": [
    "### Testes com novas frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec33043d-974f-4732-bd36-48be8b407c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 261.72ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 227ms/step\n",
      "\u001b[1m0.91\u001b[0m: Essa aí e tão piranha que eu nem pegava.\n",
      "\u001b[1m0.46\u001b[0m: Bolsonarista só se resolve na base da porrada.\n",
      "\u001b[1m0.71\u001b[0m: Esquerdista só se resolve na base da porrada.\n",
      "\u001b[1m0.99\u001b[0m: Seu preto sujo nojento\n",
      "\u001b[1m0.67\u001b[0m: Só podia ser preto favelado mesmo\n",
      "\u001b[1m0.96\u001b[0m: Seu liberal safado, você vai ver.\n",
      "\u001b[1m0.63\u001b[0m: MST é tudo terrorista\n",
      "\u001b[1m0.99\u001b[0m: Vai sua bicha\n",
      "\u001b[1m0.97\u001b[0m: Essa aí é sapatão\n",
      "\u001b[1m0.34\u001b[0m: Você é um palhaço mesmo! kkkkk\n",
      "\u001b[1m0.98\u001b[0m: Miga, você é muito escrota\n",
      "\u001b[1m0.08\u001b[0m: Estarei te esperando com minha glock, pode chegar\n",
      "\u001b[1m0.86\u001b[0m: Você vai adorar a pica que eu vou botar\n",
      "\u001b[1m0.82\u001b[0m: Esses bolivianos ignorantes vem encher o saco\n",
      "\u001b[1m0.52\u001b[0m: Vocês deviam voltar pra áfrica\n",
      "\u001b[1m0.31\u001b[0m: Lugar de mulher é na cozinha\n",
      "\u001b[1m0.15\u001b[0m: Você é bandido, e bandido bom é bandido morto!\n",
      "\u001b[1m0.47\u001b[0m: ceh bandido badido bom e bandido morto\n",
      "\u001b[1m0.53\u001b[0m: Empresta seu cabelo pra eu ariar uma panela\n",
      "\u001b[1m0.57\u001b[0m: Macaco\n",
      "\u001b[1m0.49\u001b[0m: macaco\n",
      "\u001b[1m0.54\u001b[0m: Tá com fome, eu te dou uma banana kkkkk\n",
      "\u001b[1m0.06\u001b[0m: condizente com o cérebro de quem apóia ladrões!! Não se pode esperar muito…\n",
      "0.6082 +/- 0.0603\n"
     ]
    }
   ],
   "source": [
    "bad_texts = ['Essa aí e tão piranha que eu nem pegava.',\n",
    "             'Bolsonarista só se resolve na base da porrada.',\n",
    "             'Esquerdista só se resolve na base da porrada.',\n",
    "             'Seu preto sujo nojento',\n",
    "             'Só podia ser preto favelado mesmo',\n",
    "             'Seu liberal safado, você vai ver.',\n",
    "             'MST é tudo terrorista',\n",
    "             'Vai sua bicha',\n",
    "             'Essa aí é sapatão',\n",
    "             'Você é um palhaço mesmo! kkkkk',\n",
    "             'Miga, você é muito escrota',\n",
    "             'Estarei te esperando com minha glock, pode chegar',\n",
    "             'Você vai adorar a pica que eu vou botar',\n",
    "             'Esses bolivianos ignorantes vem encher o saco',\n",
    "             'Vocês deviam voltar pra áfrica',\n",
    "             'Lugar de mulher é na cozinha',\n",
    "             'Você é bandido, e bandido bom é bandido morto!',\n",
    "             'ceh bandido badido bom e bandido morto',\n",
    "             'Empresta seu cabelo pra eu ariar uma panela',\n",
    "             'Macaco',\n",
    "             'macaco',\n",
    "             'Tá com fome, eu te dou uma banana kkkkk',\n",
    "             'condizente com o cérebro de quem apóia ladrões!! Não se pode esperar muito…']\n",
    "\n",
    "bad_rates = rate_speech_for_hate(model, tokenizer, bad_texts)\n",
    "bad_labels = ['{:.2f}'.format(x) for x in bad_rates]\n",
    "xd.print_string_series(pd.Series(bad_texts, index=bad_labels))\n",
    "print('{:.4f} +/- {:.4f}'.format(np.mean(bad_rates), np.std(bad_rates) / np.sqrt(len(bad_rates))))\n",
    "\n",
    "#bad_rates = rate_speech_for_hate(model2, tokenizer, bad_texts)\n",
    "#bad_labels = ['{:.2f}'.format(x) for x in bad_rates]\n",
    "#xd.print_string_series(pd.Series(bad_texts, index=bad_labels))\n",
    "#print('{:.4f} +/- {:.4f}'.format(np.mean(bad_rates), np.std(bad_rates) / np.sqrt(len(bad_rates))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "736b4f85-4976-4542-a6e6-24f6feb7b090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 238.83ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 275ms/step\n",
      "\u001b[1m0.15\u001b[0m: Piranha é o nome de um peixe\n",
      "\u001b[1m0.05\u001b[0m: Bolsonarista não respeita a democracia\n",
      "\u001b[1m0.13\u001b[0m: Esquerdista não respeita a democracia\n",
      "\u001b[1m0.67\u001b[0m: O lençol é sujo e nojento\n",
      "\u001b[1m0.34\u001b[0m: A polícia só mata preto e favelado\n",
      "\u001b[1m0.86\u001b[0m: Ele é o liberal mais safado que eu conheço.\n",
      "\u001b[1m0.11\u001b[0m: Al Quaeda são terroristas\n",
      "\u001b[1m0.55\u001b[0m: A bichinha miou tanto que deu uma dó!\n",
      "\u001b[1m0.58\u001b[0m: E aquele sapatão do palhaço?\n",
      "\u001b[1m0.09\u001b[0m: Tinha uns palhaços muito engraçados no circo ontem.\n",
      "\u001b[1m0.14\u001b[0m: Boa miga! Tamo junto\n",
      "\u001b[1m0.09\u001b[0m: To te esperando com um cafezinho, pode chegar\n",
      "\u001b[1m0.08\u001b[0m: Você vai adorar a grana que eu vou botar\n",
      "\u001b[1m0.33\u001b[0m: Fico com muita dor quando uma abelha me pica\n",
      "\u001b[1m0.20\u001b[0m: Os bolivianos viajam com um saco ao invês de mochila\n",
      "\u001b[1m0.17\u001b[0m: Vamos voltar à áfrica\n",
      "\u001b[1m0.39\u001b[0m: Lugar de mulher é onde ela quiser\n",
      "\u001b[1m0.01\u001b[0m: Não gostei nada da sua última proposta, com exceção, talvez, da parte 2.\n",
      "\u001b[1m0.02\u001b[0m: n gostei da sua proposta com ecessao da parte 2.\n",
      "\u001b[1m0.04\u001b[0m: dizem que há corrupção no governo Bolsonaro\n",
      "\u001b[1m0.06\u001b[0m: diz q a corupcao no gov bolsonaro\n",
      "\u001b[1m0.48\u001b[0m: Mas esse bombril é tão ruim que não dá nem pra ariar panela\n",
      "\u001b[1m0.22\u001b[0m: Cada macaco no seu galho\n",
      "\u001b[1m0.19\u001b[0m: Com o preço da banana eu tô é com fome\n",
      "\u001b[1m0.01\u001b[0m: Bola para frente tudo tem seu tempo e a Hora vai chegar\n",
      "\u001b[1m0.05\u001b[0m: Para de firulas vamos para a realidade, que está muito distante da sua existência!!\n",
      "\u001b[1m0.03\u001b[0m: Votei em você e decepcionei. Te parabenizo por chegar tão longe. Mas p governador, me desculpe. O ES merece mais.\n",
      "0.2241 +/- 0.0429\n"
     ]
    }
   ],
   "source": [
    "good_texts = ['Piranha é o nome de um peixe',\n",
    "              'Bolsonarista não respeita a democracia',\n",
    "              'Esquerdista não respeita a democracia',\n",
    "              'O lençol é sujo e nojento',\n",
    "              'A polícia só mata preto e favelado',\n",
    "              'Ele é o liberal mais safado que eu conheço.',\n",
    "              'Al Quaeda são terroristas',\n",
    "              'A bichinha miou tanto que deu uma dó!',\n",
    "              'E aquele sapatão do palhaço?',\n",
    "              'Tinha uns palhaços muito engraçados no circo ontem.',\n",
    "              'Boa miga! Tamo junto',\n",
    "              'To te esperando com um cafezinho, pode chegar',\n",
    "              'Você vai adorar a grana que eu vou botar',\n",
    "              'Fico com muita dor quando uma abelha me pica',\n",
    "              'Os bolivianos viajam com um saco ao invês de mochila',\n",
    "              'Vamos voltar à áfrica',\n",
    "              'Lugar de mulher é onde ela quiser',\n",
    "              'Não gostei nada da sua última proposta, com exceção, talvez, da parte 2.',\n",
    "              'n gostei da sua proposta com ecessao da parte 2.',\n",
    "              'dizem que há corrupção no governo Bolsonaro',\n",
    "              'diz q a corupcao no gov bolsonaro',\n",
    "              'Mas esse bombril é tão ruim que não dá nem pra ariar panela',\n",
    "              'Cada macaco no seu galho',\n",
    "              'Com o preço da banana eu tô é com fome',\n",
    "              'Bola para frente tudo tem seu tempo e a Hora vai chegar',\n",
    "              'Para de firulas vamos para a realidade, que está muito distante da sua existência!!',\n",
    "              'Votei em você e decepcionei. Te parabenizo por chegar tão longe. Mas p governador, me desculpe. O ES merece mais.']\n",
    "\n",
    "good_rates = rate_speech_for_hate(model, tokenizer, good_texts)\n",
    "good_labels = ['{:.2f}'.format(x) for x in good_rates]\n",
    "xd.print_string_series(pd.Series(good_texts, index=good_labels))\n",
    "print('{:.4f} +/- {:.4f}'.format(np.mean(good_rates), np.std(good_rates) / np.sqrt(len(good_rates))))\n",
    "\n",
    "#good_rates = rate_speech_for_hate(model2, tokenizer, good_texts)\n",
    "#good_labels = ['{:.2f}'.format(x) for x in good_rates]\n",
    "#xd.print_string_series(pd.Series(good_texts, index=good_labels))\n",
    "#print('{:.4f} +/- {:.4f}'.format(np.mean(good_rates), np.std(good_rates) / np.sqrt(len(good_rates))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "284a14e8-2264-466a-a203-da608adb3075",
   "metadata": {},
   "outputs": [],
   "source": [
    "testes_df = pd.DataFrame({'text': good_texts + bad_texts, 'violence_level': list(good_rates) + list(bad_rates)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8afc2f61-4d55-4f85-a128-6e7e66834c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testes_df.sort_values('violence_level').to_csv('../../dados/processados/testes_bertimbau-hatespeech-v01', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc20906-14ac-4805-ac30-4fa539cd4a23",
   "metadata": {},
   "source": [
    "## Analisando os erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ba3f7fb4-5779-4457-9483-04dfa33b1100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 15.40ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 95s 899ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = predict_class(model, process_pandas_to_tfdataset(test_df, tokenizer, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ec015885-32da-41ec-b01f-54ceda4e4668",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = test_df.copy()\n",
    "error_df['pred'] = pd.Series(y_test_pred, index=error_df.index)\n",
    "error_df = error_df.query('label != pred')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f0c845-5972-4db0-a0ae-e37f47cdb8e3",
   "metadata": {},
   "source": [
    "### Falsos negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "16ef88ae-2fe3-4ad0-a8eb-43d4969186b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5634\u001b[0m: LIXO DO CRL\n",
      "\u001b[1m3385\u001b[0m: RT @imztiffany: Taeyeon - Dilma\n",
      "- lider da nação\n",
      "- tem muito hate \n",
      "- plastica\n",
      "- sapatão\n",
      "- apaixonada no aecio\n",
      "- mãe de todos\n",
      "- sua fav é s _\n",
      "\u001b[1m2490\u001b[0m: O que seria 'válido', então? Feminicídio? Estupro? Mercado de trabalho? Falamos disso todo dia. Poderia dedicar uma coluna a isso, então.\n",
      "\u001b[1m5499\u001b[0m: seu nome ja disse tudo e um maria mesmo\n",
      "\u001b[1m5425\u001b[0m: treina num curral Voce viu o CT pronto doente\n",
      "\u001b[1m1029\u001b[0m: Em meio a escândalos de corrupção e nepotismo, o presidente de Angola anunciou que não tentará reeleição em 2017.... https://t.co/MnLXSQS3vg\n",
      "\u001b[1m4268\u001b[0m: VAI TOMAR NO CU!!! JUDICIÁRIO É A VERGONHA DO BRASIL!!! \n",
      "REVOLTANTE!! https://t.co/WxzQR85O3o\n",
      "\u001b[1m1594\u001b[0m: Hoje em dia não pode mais praticar genocídio numa igreja que já é racismo\n",
      "\u001b[1m4008\u001b[0m: Só há uma coisa que eu detesto mais que um atrasado mental:\n",
      "Um atrasado mental q pensa que é um campeão qd está atrás de um ecrã de um PC\n",
      "\u001b[1m1134\u001b[0m: Esse cara é um lixo humano, é daqueles imbecis que acham que sabem tudo https://t.co/Ocs4E9fEV1\n",
      "\u001b[1m5047\u001b[0m: Que comentario de bosta foi esse deve acompanhar muito o futebol europeu pra fazer um comentario desse\n",
      "\u001b[1m1116\u001b[0m: Essa foi na mosca. E eu achando que o problema fosse só aqui no Brasil com essa 'geração lacre' https://t.co/RLhRV0Ofei\n",
      "\u001b[1m2764\u001b[0m: pra quem acha que sou um fdp... fdp é isso ->  http://t.co/VIAAfcT3sC hahahahaha\n",
      "\u001b[1m4734\u001b[0m: Comunista defendendo a  Democraciakkkkk esses vermelhinhos sao uma piada\n",
      "\u001b[1m1350\u001b[0m: Feliz Dia Da Mulher só p/ as mulheres brancas,pq o dia da mulher negra latino americana e caribenha,é dia 25 de julho!Segregação da esquerda\n",
      "\u001b[1m4542\u001b[0m: ninguem se importa com vc nem sua mae seu nada\n",
      "\u001b[1m2043\u001b[0m: Meu Deus, o cara tá JUSTIFICANDO ATAQUES TERRORISTAS CONTRA INOCENTES, PORRA!!! Tem que prender um vagabundo desses _ https://t.co/HyIlOOMAgc\n",
      "\u001b[1m5628\u001b[0m: Cola velcro perdeu o meu respeito\n",
      "\u001b[1m5430\u001b[0m: Mais um jogo e o flaF E Z E S sem estadione g l o b o\n",
      "\u001b[1m2597\u001b[0m: 'Parabéns pra você, mulher. Parabéns pra você que é feia, gorda, não se cuida, coitada. Que não vai arranjar... https://t.co/CEoqvg3lGa\n",
      "\u001b[1m2884\u001b[0m: Quem é mais demente, essas mães ou o jornal que pública uma MERDA dessas? https://t.co/Ed0fd0eCUy\n",
      "\u001b[1m2816\u001b[0m: PUTA QUE PARIU QUEREM DECIDIR COMO O RAPAZ DEVE CHAMAR SUA PRÓPRIA NAMORADA, VÃO SE FODER https://t.co/rrnjaD89DL\n",
      "\u001b[1m3934\u001b[0m: Se nem presidiário tem pena de estuprador (os caras são estuprados lá dentro mesmo) pq a esquerda quer que a gente tenha?\n",
      "\u001b[1m1154\u001b[0m: @Estadao @CamilaPitanga estou com @RachelSherazade. são idiotas inúteis, mamadores do dinheiro público, iludem milhões de imbecis.\n",
      "\u001b[1m1297\u001b[0m: Fala ai mariquinhas e afins.... Como vai a falta de culhão para resolver qualquer coisinha ?\n",
      "\u001b[1m5303\u001b[0m: Vou festejar a prisao desse vermebarbudo mais que o Ano Novo\n",
      "\u001b[1m204\u001b[0m: ALÔ RAPAZIADA: VAMOS RESPEITAR AS DONZELAS SEUS PORCOS BÊBADOS IMUNDOS #PAZ #CarnavalSemAssedio #usecamisinha https://t.co/Rl59UAYqqA\n",
      "\u001b[1m1184\u001b[0m: ESTAR ACORDADO\n",
      "SÁBADO DE MANHÃ\n",
      "ISSO QUE SEPARA NÓS\n",
      "(POVO HONESTO E TRABALHADOR)\n",
      "DELES\n",
      "(VAGABUNDOS DROGADOS E CORRUPTOS)\n",
      "BOM DIA BRASIL\n",
      "#PAZ\n",
      "\u001b[1m258\u001b[0m: @amandtra gente e as meninas dando biscoito, acho q vc n eh a mulher mais burra do mundo mais\n",
      "\u001b[1m4468\u001b[0m: corta na carne nada temer aqui no rj o pacote de maldade deixa juizes politicos e sanguessugas que ganham mais de  mil por mes de fora dos cortes so ferra com pobre e aposentado sabem o que vai acontecer o povo vai acordar e dessa vez nao vai ter desculpa forca e muita pancada nos pilantras sanguessugas\n",
      "\u001b[1m2629\u001b[0m: @pauloap @FelipeHamachi 'ain pq toy story mostra o capitalismo do menino que escraviza os brinquedos' \n",
      "'pq sera que o woody não é negro?'\n",
      "\u001b[1m1317\u001b[0m: FAZ ASSIM, FALA COM ELE: OU SUA MAMÃE PARA DE SE OFERECER OU PASSAREI A LINGUIÇA NELA. HONESTIDADE É SEMPRE O CAMIN _ https://t.co/dcaofcwXCK\n",
      "\u001b[1m4715\u001b[0m: Infelizmente tudo q nao presta nesse pais da ibope essa anta e prova viva disso\n",
      "\u001b[1m597\u001b[0m: @CapitalismoOP deve ter uma feminista peluda e bem gorda trabalhando no foicebook...\n",
      "\u001b[1m874\u001b[0m: #DiaDaMulher e não dia das putas aborteiras....\n",
      "\u001b[1m280\u001b[0m: amo os negros são tao gnt boa, é uma pena q pararam de vender\n",
      "\u001b[1m299\u001b[0m: A MULHER É PERFEITA: LINDA, TRABALHADORA, DÁ PAULADA NAS FEMINISTA E NÃO TEM FEICEBUK. \n",
      "ACHO QUE VOU PEDI-LÁ EM CAS _ https://t.co/7BEgP3dEdP\n",
      "\u001b[1m64\u001b[0m: acho que a Simone depende mais do natal pra sobreviver que o Papai Noel\n",
      "\u001b[1m3795\u001b[0m: RT @toiaos: @InesBolsonaro por tras do twitter só tem maconheiro, eles fazem de tudo pra tirar os reaças do site\n",
      "\u001b[1m324\u001b[0m: Angola é um drama e não uma comédia...\n",
      "\u001b[1m5632\u001b[0m: estragando a paisagem\n",
      "\u001b[1m3617\u001b[0m: RT @OficialJoao: Orgulho Hetero  Homofobia. Abs\n",
      "\u001b[1m5498\u001b[0m: Cheiro de coco aqui\n",
      "\u001b[1m4741\u001b[0m: Pq o Morosita recebe ordens externas A ordem nao chegou ainda\n",
      "\u001b[1m3467\u001b[0m: RT @jpintocoelho60: Os animais islamitas continuam a atacar em solo europeu.\n",
      "A culpa é dos governantes: traidores, criminosos!\n",
      "Só o Naciona _\n",
      "\u001b[1m4335\u001b[0m: Você é cheinha, NÃO é gostosa. Ponto. https://t.co/Dd1TcPSfye\n",
      "\u001b[1m5441\u001b[0m: Esse time em que todos gostam de ceder a cauda\n",
      "\u001b[1m4587\u001b[0m: Quer vida facilva rodar bolsinha na AvAtlantica ou na Vieira Souto Joao\n",
      "\u001b[1m5390\u001b[0m: Esse juizeco do Moro e  um canalha\n",
      "\u001b[1m3792\u001b[0m: RT @therealbunk3r: @direitafalando feliz dia das mães só pras mães de familia tradicional\n",
      "\u001b[1m1691\u001b[0m: Isso aqui a @SpOAB não vê. Mas piadinhas que o @editorahumanas faz de gorda feminista eles se preocupam... https://t.co/sAqVlHh3fo\n",
      "\u001b[1m5637\u001b[0m: Achei que a macaca vivia apenas na floresta ou no zologico\n",
      "\u001b[1m2262\u001b[0m: negras, queimem seus sutiãs, vocês estão se apropriando da cultura branca norte-americana!!!\n",
      "\u001b[1m5194\u001b[0m: MENOS UM MAS TEM QUE QUEIMAR LOGO O CORPO DELE ANTES DE CHEGAR NA PORTA DO NEM SEI E POLITICO MESMO  DO INFERNO\n",
      "\u001b[1m1541\u001b[0m: @5gu @caiquepala Tinha que ser gorda, né?\n",
      "\u001b[1m5554\u001b[0m: quando sua me devolver o troco de R  pelo servico oral que ela me fez\n"
     ]
    }
   ],
   "source": [
    "xd.print_string_series(error_df.query('label == 1')['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6907002d-85e5-4e36-84a4-6679cc923625",
   "metadata": {},
   "source": [
    "### Falsos positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "65980102-bd7e-4308-8f50-e082e72de92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2081\u001b[0m: MINHA TATARAVÓ ERA NEGRA!!! TENHO SANGUE NEGRO\n",
      "\u001b[1m5072\u001b[0m: MARIAS NOS CIO  MINHAS PRESAS PREDILETAS VOU ME ESBANJAR EM DEVORALAS\n",
      "\u001b[1m2242\u001b[0m: Não tinha reparado com aquela menina é gata\n",
      "\u001b[1m4750\u001b[0m: a batata dela ta assando e ja fazendo plano de fuga\n",
      "\u001b[1m4595\u001b[0m: Engracado e que se voce disputar emprego com eles voce perdera\n",
      "\u001b[1m2390\u001b[0m: O gay assumido bem resolvido é bem mais @homemdeverdade do que frangas arrogantes, dissimulados que não enfrentam a própria cara no espelho!\n",
      "\u001b[1m1380\u001b[0m: FICA TRANQUILO IRMÃO VÁRIAS DAS MINHAS TRANZAS JÁ ACABAM COM CHORO E ZOAÇÃO FAZ PARTE @JOAQUINRESPONDE https://t.co/yGwTy17tSJ\n",
      "\u001b[1m4912\u001b[0m: VAI NO CEMINTERIO ESTA MAIS LOTADO CHEIO DE INOCENTES MORTOS PELAS MAOS DESSES VERMES\n",
      "\u001b[1m4263\u001b[0m: vai pra cuba\n",
      "\u001b[1m1616\u001b[0m: Homem que é homem come doritos de pimenta com geléia extra-forte de pimenta e guaraná ice.\n",
      "\u001b[1m5234\u001b[0m: Os netos que devem ter vergonha dele\n",
      "\u001b[1m3490\u001b[0m: RT @kordeidoI: 6- emily fields\n",
      "só se fode\n",
      "emaya era lindo sim \n",
      "maria sapatão\n",
      "merece bem mais \n",
      "ela toma tanto no cu que as vezes eu acho qu _\n",
      "\u001b[1m2027\u001b[0m: Meninas tem q ser ensinadas q sentimentalismo é merda, a Disney é golpista (não existe príncipe) e cavalheirismo é frescura no rabo\n",
      "\u001b[1m1615\u001b[0m: Homem que é homem brinca de girocóptero no banheiro da casa da sogra.\n",
      "\u001b[1m736\u001b[0m: Como vc se sente @lolaescreva roubando o meu dinheiro d'um país que não tem leito em hospital direito? Sua canalha\n",
      "\u001b[1m5060\u001b[0m: PARE COM ESSE VEXAME GENTE DEIXA ESTE CARA DE LADO\n",
      "\u001b[1m4571\u001b[0m: Cara que bota preco em ideal nao e idealistaE mercenario\n",
      "\u001b[1m4252\u001b[0m: @ursinho_branco puta merda. Que sonho\n",
      "\u001b[1m4774\u001b[0m: OS PETRALHAS ESTAO ARRUMANDO ESCONDERIJO\n",
      "\u001b[1m2827\u001b[0m: Qnd as feministas vierem me ofender, não vou nem rebater, só vou dar RT.\n",
      "\u001b[1m3965\u001b[0m: Ser mulher é ter que provar todo dia que não é burra e é tão competente quanto qualquer um.\n",
      "\u001b[1m4592\u001b[0m: Outro seu Bertin lexotankkkVixemas vc ainda e mortadela meu filho\n",
      "\u001b[1m846\u001b[0m: Desejou feliz dia das mulé o cara q chama mulher de burra o resto do ano\n",
      "\u001b[1m1225\u001b[0m: eu devo ser mt feia, pq gorda eu já sou...\n",
      "\u001b[1m1769\u001b[0m: @JornalOGlobo o que essa palhaça de cara pintada ta fazendo capa! Elas não representam a mulher brasileira!  Vaza F _ https://t.co/wStSCAQjHl\n",
      "\u001b[1m4302\u001b[0m: vcs sabem como minhas irmãs fazem para saber q estão grávidas? enfiam uma banana na xana, se voltar mordida é porque estão.\n"
     ]
    }
   ],
   "source": [
    "xd.print_string_series(error_df.query('label == 0')['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5267d24-1ecc-4ca6-9854-be0a20e7947b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc61e036-7d0b-4c14-aece-63df0f7eed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speechwrapper as sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0447fe7-c688-4993-a6ed-0fc801454d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer from neuralmind/bert-base-portuguese-cased\n",
      "Loading trained model: ../modelos/bertimbau-hatespeech-v01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../modelos/bertimbau-hatespeech-v01 were not used when initializing TFBertForSequenceClassification: ['dropout_151']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at ../modelos/bertimbau-hatespeech-v01.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "wrapper = sw.HateSpeechModel('../../modelos/bertimbau-hatespeech-v01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bd4a606-71a9-4668-be57-2e4ce0bdee65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 287.12ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.09299637, 0.00845698], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exemplos = ['To te esperando com um cafezinho, pode chegar', 'Não gostei nada da sua última proposta, com exceção, talvez, da parte 2.']\n",
    "wrapper.predict_proba(exemplos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce000652-255e-4b59-86f3-cf93a58b5aaa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f48da2e-dffd-4fce-9ec1-c9764d6a5683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 12:26:46.541941: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-04 12:26:46.541963: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/skems/system/envs/ceweb/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import hatepred as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9262dddc-182b-49ab-bacf-74d878594839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 12:15:57.885133: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-08-04 12:15:57.885175: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: glitterbu\n",
      "2022-08-04 12:15:57.885181: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: glitterbu\n",
      "2022-08-04 12:15:57.885279: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 390.154.0\n",
      "2022-08-04 12:15:57.885300: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 390.151.0\n",
      "2022-08-04 12:15:57.885306: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 390.151.0 does not match DSO version 390.154.0 -- cannot find working devices in this configuration\n",
      "2022-08-04 12:15:57.885521: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some layers from the model checkpoint at ../modelos/bertimbau-hatespeech-v01 were not used when initializing TFBertForSequenceClassification: ['dropout_151']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at ../modelos/bertimbau-hatespeech-v01.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Carrega tokenizer:\n",
    "tokenizer  = hp.AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=False)\n",
    "# Carrega o modelo:\n",
    "model = hp.TFAutoModelForSequenceClassification.from_pretrained('../../modelos/bertimbau-hatespeech-v01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1729d3cb-9de4-447d-87c3-efdedd86e3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 61.48ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 6s 223ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.9067946 , 0.4641457 , 0.7122503 , 0.9855008 , 0.66725206,\n",
       "       0.96393603, 0.6290632 , 0.98527336, 0.96865195, 0.3382687 ,\n",
       "       0.9841449 , 0.07876287, 0.8605168 , 0.8150324 , 0.51905274,\n",
       "       0.31016403, 0.14504538, 0.4707777 , 0.5290753 , 0.57215285,\n",
       "       0.4866424 , 0.5380142 , 0.05814871], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp.rate_speech_for_hate(model, tokenizer, bad_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a064141c-1767-4f01-8bf0-edd82709af0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8969fa0b-d0a7-4df2-972c-973f5df27372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 12:17:55.428503: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-04 12:17:55.428527: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/skems/system/envs/ceweb/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import speechwrapper as sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "321d0d88-5bd0-4ddb-afd9-dd4921801265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer from neuralmind/bert-base-portuguese-cased\n",
      "Loading trained model: ../modelos/bertimbau-hatespeech-v01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 12:18:08.963943: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-08-04 12:18:08.963975: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: glitterbu\n",
      "2022-08-04 12:18:08.963982: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: glitterbu\n",
      "2022-08-04 12:18:08.964059: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 390.154.0\n",
      "2022-08-04 12:18:08.964080: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 390.151.0\n",
      "2022-08-04 12:18:08.964086: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 390.151.0 does not match DSO version 390.154.0 -- cannot find working devices in this configuration\n",
      "2022-08-04 12:18:08.964334: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some layers from the model checkpoint at ../modelos/bertimbau-hatespeech-v01 were not used when initializing TFBertForSequenceClassification: ['dropout_151']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at ../modelos/bertimbau-hatespeech-v01.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "wrapper = sw.HateSpeechModel('../../modelos/bertimbau-hatespeech-v01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fa9ee42-d040-4722-a8ea-dffdc9d01c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 101.83ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 6s 266ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.14720546, 0.05058111, 0.13043758, 0.66963   , 0.3385753 ,\n",
       "       0.8626306 , 0.11031707, 0.55077153, 0.58265865, 0.09415061,\n",
       "       0.13883495, 0.09299637, 0.08486506, 0.33029503, 0.19715138,\n",
       "       0.17266637, 0.3865594 , 0.00845698, 0.01503846, 0.04057452,\n",
       "       0.06342246, 0.4787394 , 0.22150485, 0.19421276, 0.00696036,\n",
       "       0.05128425, 0.02889735], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp.rate_speech_for_hate(wrapper.model, wrapper.tokenizer, good_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd685e92-371c-4a02-b0fb-5619f540ab4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 252.18ba/s]\n"
     ]
    }
   ],
   "source": [
    "tfd = hp.process_pandas_to_tfdataset(hp.pd.DataFrame({'text': bad_texts, 'label': [1] * len(bad_texts)}), wrapper.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74f7f7b5-854a-4cea-80ac-535cf50113e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 208ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.4707777 , 0.9841449 , 0.14504538, 0.5380142 , 0.9855008 ,\n",
       "       0.96865195, 0.46414563, 0.33826876, 0.96393603, 0.4866424 ,\n",
       "       0.66725206, 0.5290753 , 0.57215285, 0.8150324 , 0.05814879,\n",
       "       0.9067946 , 0.62906325, 0.3101641 , 0.7122503 , 0.98527336,\n",
       "       0.5190528 , 0.8605168 , 0.07876287], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.predict_proba_from_tfd(tfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f5fe583-9b74-4b7e-a17f-89d88f270a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://16a7e2e5-d037-48ca-aa5a-7645064e1c56/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://16a7e2e5-d037-48ca-aa5a-7645064e1c56/assets\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 246.96ba/s]\n"
     ]
    }
   ],
   "source": [
    "tfd = wrapper.process_pandas_to_tfdataset(hp.pd.DataFrame({'text': bad_texts, 'label': [1] * len(bad_texts)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cfce466-2b8d-461f-bf5e-9b1598e91fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://f2055a48-31e6-45e2-8fc4-225320b14f5c/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://f2055a48-31e6-45e2-8fc4-225320b14f5c/assets\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.49ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 308ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.14720546, 0.05058111, 0.13043758, 0.66963   , 0.3385753 ,\n",
       "       0.8626306 , 0.11031707, 0.55077153, 0.58265865, 0.09415061,\n",
       "       0.13883495, 0.09299637, 0.08486506, 0.33029503, 0.19715138,\n",
       "       0.17266637, 0.3865594 , 0.00845698, 0.01503846, 0.04057452,\n",
       "       0.06342246, 0.4787394 , 0.22150485, 0.19421276, 0.00696036,\n",
       "       0.05128425, 0.02889735], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(good_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38874e9-c64e-4399-b376-fddc737251db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
