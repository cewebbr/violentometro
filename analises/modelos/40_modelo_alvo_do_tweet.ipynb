{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxEWIBJ7Uv3g"
   },
   "source": [
    "# Criando modelo p/ identificar alvo do tweet c/ BERT pré-treinado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Voltar ao Índice](../00_indice.ipynb)\n",
    "\n",
    "O objetivo deste notebook era criar um modelo de arquitetura BERT que identificasse o alvo de um tweet (se o candidato mencionado ou não), tal qual descrito no notebook sobre o [modelo de ML de mesmo propósito](30_modelo_baseline_objeto_do_tweet.ipynb).\n",
    "\n",
    "**Resultado:** A performance obtida na amostra de teste foi muito ruim, provavelmente devido ao baixo número de instâncias de teste. Vamos utilizar o [modelo de machine learning](30_modelo_baseline_objeto_do_tweet.ipynb) mais simples.\n",
    "\n",
    "**ATTENTION:** This notebook uses data that is not available in this project due to legal restrictions by the Brazilian Personal Data Protection Law ([LGPD](https://www.planalto.gov.br/ccivil_03/_ato2015-2018/2018/lei/l13709.htm))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AhaiLEsUUv3k"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 09:41:47.591844: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/home/hxavier/temp/violentometro/env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# Hugging Face:\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from datasets import Dataset\n",
    "from transformers import DefaultDataCollator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyBulMSvUv3n"
   },
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GeWCwDtKUv3o"
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "### Splitting datasets into random sets ###\n",
    "###########################################\n",
    "\n",
    "def shuffled_pos(length, seed):\n",
    "    \"\"\"\n",
    "    Return indices from 0 to `length` - 1 in a shuffled state, given random `seed`.\n",
    "    \"\"\"\n",
    "    return np.random.RandomState(seed=seed).permutation(length)\n",
    "\n",
    "\n",
    "def random_index_sets(size, set_fracs, seed):\n",
    "    \"\"\"\n",
    "    Return sets of random indices (from 0 to `size` - 1) with lengths \n",
    "    given by ~ `size` * `set_fracs`.\n",
    "    \n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    \n",
    "    size : int\n",
    "        The size of the index list to split into sets.\n",
    "        \n",
    "    set_fracs : iterable\n",
    "        The fractions of the list of indices that each index set \n",
    "        should contain. \n",
    "    \n",
    "    seed : int\n",
    "        The seed for the random number generator.\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    indices : tuple of arrays\n",
    "        The indices for each set.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert np.isclose(np.sum(set_fracs), 1), '`set_fracs` should add up to one.'\n",
    "    \n",
    "    # Create randomized list of indices:\n",
    "    shuffled_indices = shuffled_pos(size, seed)\n",
    "    \n",
    "    \n",
    "    indices   = []\n",
    "    set_start = [0]\n",
    "    # Determine the sizes of the sets:\n",
    "    set_sizes = [round(size * f) for f in set_fracs]\n",
    "    set_sizes[0] = size - sum(set_sizes[1:])\n",
    "    assert np.sum(set_sizes) == size, 'Set sizes should add up to total size.'\n",
    "    \n",
    "    for i in range(0, len(set_fracs) - 1):\n",
    "        # Select indices for a set:\n",
    "        set_start.append(set_start[i] + set_sizes[i])\n",
    "        set_indices = shuffled_indices[set_start[i]:set_start[i + 1]]\n",
    "        indices.append(set_indices)\n",
    "        assert len(indices[i]) == len(set(indices[i])), 'There are repeating indices in a set.'\n",
    "        \n",
    "    # Select the indices for the last set:\n",
    "    indices.append(shuffled_indices[set_start[-1]:])\n",
    "    assert len(set(np.concatenate(indices))) == sum([len(i) for i in indices]), \\\n",
    "    'There are common indices between sets.'\n",
    "    \n",
    "    return tuple(indices)\n",
    "\n",
    "\n",
    "def random_set_split(df, set_fracs, seed):\n",
    "    \"\"\"\n",
    "    Split a DataFrame into randomly selected disjoint and complete sets.\n",
    "    \n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    \n",
    "    df : Pandas DataFrame\n",
    "        The dataframe to split into a complete and disjoint set of sub-sets.\n",
    "        \n",
    "    set_fracs : array-like\n",
    "        The fraction of `df` that should be put into each set. The length of \n",
    "        `set_fracs` determines the number of sub-sets to create.\n",
    "    \n",
    "    seed : int\n",
    "        The seed for the random number generator used to split `df`.\n",
    "        \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    A tuple of DataFrames, one for each fraction in `set_fracs`, in that order.\n",
    "    \"\"\"\n",
    "    # Get positional indices for each set:\n",
    "    sets_idx = random_index_sets(len(df), set_fracs, seed)\n",
    "    \n",
    "    return tuple(df.iloc[idx] for idx in sets_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "S-Q8IyPiUv3q"
   },
   "outputs": [],
   "source": [
    "def process_pandas_to_tfdataset(df, tokenizer, max_length=80, shuffle=True, text_col='text', target_col='label', batch_size=8):\n",
    "    \"\"\"\n",
    "    Prepare NLP data in a Pandas DataFrame to be used \n",
    "    in a TensorFlow transformer model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        The corpus, containing the columns `text_col` \n",
    "        (the sentences) and `target_col` (the labels).\n",
    "    tokenizer : HuggingFace AutoTokenizer\n",
    "        A tokenizer loaded from \n",
    "        `transformers.AutoTokenizer.from_pretrained()`.\n",
    "    max_length : int\n",
    "        Maximum length of the sentences (smaller \n",
    "        sentences will be padded and longer ones\n",
    "        will be truncated). This is required for \n",
    "        training, so batches have instances of the\n",
    "        same shape.\n",
    "    shuffle : bool\n",
    "        Shuffle the dataset order when loading. \n",
    "        Recommended True for training, False for \n",
    "        validation/evaluation.\n",
    "    text_col : str\n",
    "        Name of `df` column containing the sentences.\n",
    "    target_col : str\n",
    "        Name of `df` column containing the labels of \n",
    "        the sentences.\n",
    "    batch_size : int\n",
    "        The size of the batch in the output \n",
    "        tensorflow dataset.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tf_dataset : TF dataset\n",
    "        A dataset that can be fed into a transformer \n",
    "        model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Security checks:\n",
    "    renamed_df = df.rename({target_col:'labels'}, axis=1) # Hugging Face requer esse nome p/ y.\n",
    "    \n",
    "    # Define função para processar os dados com o tokenizador:\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[text_col], padding=True, max_length=max_length, truncation=True)\n",
    "    \n",
    "    # pandas -> hugging face:\n",
    "    hugging_set = Dataset.from_pandas(renamed_df)\n",
    "    # texto -> sequência de IDs: \n",
    "    encoded_set = hugging_set.map(tokenize_function, batched=True)\n",
    "    # hugging face -> tensorflow dataset:\n",
    "    data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "    tf_dataset = encoded_set.to_tf_dataset(columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"], label_cols=[\"labels\"], shuffle=shuffle, collate_fn=data_collator, batch_size=batch_size)\n",
    "    \n",
    "    return tf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_aL_-u_oUv3q"
   },
   "outputs": [],
   "source": [
    "def gen_tensorboard_callback(root_dir, run_name):\n",
    "    \"\"\"\n",
    "    Return a tensorboard callback with log dir given \n",
    "    by `root_dir` + `run_name`. It avoids logging \n",
    "    to a pre-existing log inadvertently. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Root dir should exist. Check it:\n",
    "    if os.path.isdir(root_dir) == False:\n",
    "        raise Exception(\"`root_dir` {} is unknown.\".format(root_dir))\n",
    "    \n",
    "    # Build path to log:\n",
    "    fullpath = os.path.join(root_dir, run_name)\n",
    "    \n",
    "    # Check if log already exists:\n",
    "    already_exists = os.path.isdir(fullpath)\n",
    "    if already_exists:\n",
    "        \n",
    "        # If exists, ask if it sohuld continue:\n",
    "        go_on = input(\"Run log '{}' already exists. Continue (y/n)?\".format(run_name))\n",
    "        if go_on == 'y' or go_on == 'Y':\n",
    "            return tf.keras.callbacks.TensorBoard(fullpath)\n",
    "       \n",
    "        else:\n",
    "            raise Exception('Abort so not to mess with tensorboard log.')\n",
    "    \n",
    "    else:\n",
    "        return tf.keras.callbacks.TensorBoard(fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wW_bPXvSJYFd"
   },
   "outputs": [],
   "source": [
    "def predict_proba(model, tf_dataset):\n",
    "    \"\"\"\n",
    "    Use the provided model to compute the\n",
    "    probability that each instance is \n",
    "    in the positive class (1 in a binary \n",
    "    classification).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : TFBertForSequenceClassification\n",
    "        A Hugging Face implementation of a \n",
    "        Tensorflow transformer model.\n",
    "    tf_dataset : Tensorflow Dataset\n",
    "        The data for which to make predictions.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    probs : array\n",
    "        Probability that the corresponding \n",
    "        instance falls in the positive class\n",
    "        (y = 1).\n",
    "    \"\"\"\n",
    "\n",
    "    tf_predict = model.predict(tf_dataset).logits\n",
    "    probs = tf.sigmoid(tf_predict)[:,0].numpy()\n",
    "    \n",
    "    return probs\n",
    "\n",
    "\n",
    "def predict_class(model, tf_dataset, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Use the provided model to predict\n",
    "    the class of each instance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : TFBertForSequenceClassification\n",
    "        A Hugging Face implementation of a \n",
    "        Tensorflow transformer model.\n",
    "    tf_dataset : Tensorflow Dataset\n",
    "        The data for which to make predictions.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    preds : array\n",
    "        Predicted class for the corresponding\n",
    "        instances.\n",
    "    \"\"\"\n",
    "\n",
    "    probs = predict_proba(model, tf_dataset)\n",
    "    preds = (probs > threshold).astype(int)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations(annotated_files):\n",
    "    annotated_df = pd.concat([pd.read_csv(f) for f in annotated_files], ignore_index=True)\n",
    "    annotated_df = annotated_df.loc[~annotated_df['not_the_target'].isnull()]\n",
    "    annotated_df['not_the_target'] = annotated_df['not_the_target'].astype(int)\n",
    "    return annotated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvjnMPEOUv3r"
   },
   "source": [
    "## Carregando o BERTimbau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "buWofr5TUv3s",
    "outputId": "56f6ed11-d087-4042-8037-056c788d6d49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 09:42:06.684114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-16 09:42:06.699801: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2023-02-16 09:42:06.699812: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-16 09:42:06.700540: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier', 'bert/pooler/dense/bias:0', 'bert/pooler/dense/kernel:0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define o modelo em questão:\n",
    "model_name = 'neuralmind/bert-base-portuguese-cased'\n",
    "# Carregando:\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_name, do_lower_case=False)\n",
    "model      = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
    "#model = TFAutoModelForSequenceClassification.from_pretrained('../../modelos/bertimbau-hatespeech-v01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUFcDa5OUv3u"
   },
   "source": [
    "## Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZFLE75DaUv3u"
   },
   "outputs": [],
   "source": [
    "# Carrega os dados:\n",
    "#annotated_files = ['../../dados/processados/tweets_classificados_por_objeto_anotados.csv',    # Dados não criptografados.\n",
    "#                   '../../dados/processados/tweets_classificados_por_objeto_2_anotados.csv',\n",
    "#                   '../../dados/processados/tweets_classificados_por_objeto_3_anotados.csv']\n",
    "annotated_files = ['../../dados/processados/tweets_classificados_por_objeto_anotados_encrypted.csv', \n",
    "                   '../../dados/processados/tweets_classificados_por_objeto_2_anotados_encrypted.csv',\n",
    "                   '../../dados/processados/tweets_classificados_por_objeto_3_anotados_encrypted.csv']\n",
    "annotated_df = load_annotations(annotated_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PhkEC1VGUv3v"
   },
   "outputs": [],
   "source": [
    "# Separa a amostra:\n",
    "train_df, val_df, test_df = random_set_split(annotated_df, [0.7, 0.15, 0.15], 614)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando dados p/ teste do modelo:\n",
    "#val_df.to_csv('../../dados/processados/hatespeech_fortuna3+offcombr2_val_seed1323.csv', index=False)\n",
    "#test_df.to_csv('../../dados/processados/hatespeech_fortuna3+offcombr2_test_seed1323.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "6250c40f8e114db9a226db01ce2a1d84",
      "bae291373ce24ce1a0594334ae2ce414",
      "734e8736e4b948c790536a524aaf7f01",
      "9d91c870729c4cfba700acda20eeef0d",
      "4e62dbd2382d4d15aa49cff8de61be53",
      "cd5d6dfa298b4756a6d4e714cdefedd5",
      "b2ae2782be834feeaffde4e50fc0e3f2",
      "585fa61fe96b4c11bf0163b3ea646cd2",
      "976513a8ec674d3fb16cb04d8166533a",
      "bfe43e79dae34624bad82ab5cab0e4bf",
      "28f9d87645184fca8b8305167b4c2539",
      "dd64a6ae604847808188a63f60b9dd6e",
      "3f51f1a3231d4b4eb20b407b5664f78f",
      "d390ffb74d5044f8b0c847c30191957c",
      "11b3d04dc0f3446d8b7d007aaa923865",
      "7f0a57db827b4b47a492759ac218377d",
      "8b6ca3c2ac2c4f4c88c9528f52f075a3",
      "707bd0c951ff46d88df758e3dfc7faec",
      "28ac59e6f3ad4442837e470d63a5913a",
      "3fba13def095450f9c9b2dd0c65f5fd0",
      "204739ce239b47cb86643f556939e81f",
      "0a3754eebd83498eaf19c4dbd836d6fb"
     ]
    },
    "id": "ft2GXmXXUv3v",
    "outputId": "32889dbc-1eef-4451-cfbe-945a74c0f08c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 31.79ba/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 107.07ba/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 119.49ba/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokeniza os textos e os coloca no formato do Tensorflow Dataset:\n",
    "train_tfd = process_pandas_to_tfdataset(train_df, tokenizer, batch_size=32, shuffle=True, target_col='not_the_target')\n",
    "val_tfd   = process_pandas_to_tfdataset(val_df, tokenizer, batch_size=32, shuffle=False, target_col='not_the_target')\n",
    "test_tfd  = process_pandas_to_tfdataset(test_df, tokenizer, batch_size=32, shuffle=False, target_col='not_the_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rB0mOLwWZoa",
    "outputId": "128b2c6e-461c-405e-959d-e6bf581cd18f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7422680412371134"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acurácia mínima (chute a moda):\n",
    "(val_df['not_the_target'] == 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlfYNHIIUv3w"
   },
   "source": [
    "## Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6F9uJXeyKyEN"
   },
   "outputs": [],
   "source": [
    "# Parâmetros do treinamento:\n",
    "model_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True) # O Hugging Face não coloca uma função de ativação na última camada, por isso usaremos 'logits'.\n",
    "metrics = ['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nctJ4r_K5Jc"
   },
   "source": [
    "### Início do treinamento: ajuste grosso da última camada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hP1XMQFzTMym"
   },
   "source": [
    "Nesta etapa, não esperamos que haja overfitting pois o modelo é muito simples (basicamente uma regressão logística sobre as features criadas pelo BERT. Na verdade, devemos ter um underfitting. Podemos treinar à vontade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "drPqt_vTUv3w",
    "outputId": "02914e17-e776-42c6-b86a-500730fa326b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108923136 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  769       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,923,905\n",
      "Trainable params: 769\n",
      "Non-trainable params: 108,923,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Preparando o modelo com o BERT congelado:\n",
    "optimizer  = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "model.get_layer('bert').trainable = False\n",
    "model.compile(optimizer, model_loss, metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "SNHgYNyPUv3x"
   },
   "outputs": [],
   "source": [
    "# Monitoramento com o Tensorboard \n",
    "# tensorboard --logdir=tensor_logs/\n",
    "#board = gen_tensorboard_callback('tensor_logs/', 'first_try')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9E2vMgRzsh1_",
    "outputId": "9de84bfb-c542-4c68-e863-cd81784c7d5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "15/15 [==============================] - 15s 286ms/step - loss: 0.4618 - accuracy: 0.8496 - val_loss: 0.5475 - val_accuracy: 0.7423\n",
      "Epoch 2/40\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.4184 - accuracy: 0.8496 - val_loss: 0.5574 - val_accuracy: 0.7423\n",
      "Epoch 3/40\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.3856 - accuracy: 0.8496 - val_loss: 0.5859 - val_accuracy: 0.7423\n",
      "Epoch 4/40\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.3893 - accuracy: 0.8496 - val_loss: 0.5216 - val_accuracy: 0.7423\n",
      "Epoch 5/40\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.3804 - accuracy: 0.8496 - val_loss: 0.4977 - val_accuracy: 0.7423\n",
      "Epoch 6/40\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.3778 - accuracy: 0.8496 - val_loss: 0.5295 - val_accuracy: 0.7423\n",
      "Epoch 7/40\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.3472 - accuracy: 0.8496 - val_loss: 0.4801 - val_accuracy: 0.7526\n",
      "Epoch 8/40\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.3466 - accuracy: 0.8496 - val_loss: 0.6230 - val_accuracy: 0.7423\n",
      "Epoch 9/40\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.3665 - accuracy: 0.8584 - val_loss: 0.4687 - val_accuracy: 0.7526\n",
      "Epoch 10/40\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.3426 - accuracy: 0.8562 - val_loss: 0.5157 - val_accuracy: 0.7423\n",
      "Epoch 11/40\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.3421 - accuracy: 0.8540 - val_loss: 0.5220 - val_accuracy: 0.7423\n",
      "Epoch 12/40\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.3509 - accuracy: 0.8473 - val_loss: 0.4959 - val_accuracy: 0.7526\n",
      "Epoch 13/40\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.3341 - accuracy: 0.8584 - val_loss: 0.4791 - val_accuracy: 0.7526\n",
      "Epoch 14/40\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.3493 - accuracy: 0.8496 - val_loss: 0.5459 - val_accuracy: 0.7423\n",
      "Epoch 15/40\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.3327 - accuracy: 0.8584 - val_loss: 0.5846 - val_accuracy: 0.7423\n",
      "Epoch 16/40\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.3216 - accuracy: 0.8562 - val_loss: 0.4929 - val_accuracy: 0.7423\n",
      "Epoch 17/40\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.3232 - accuracy: 0.8518 - val_loss: 0.5614 - val_accuracy: 0.7423\n",
      "Epoch 18/40\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.3195 - accuracy: 0.8562 - val_loss: 0.4690 - val_accuracy: 0.7526\n",
      "Epoch 19/40\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.3418 - accuracy: 0.8562 - val_loss: 0.4490 - val_accuracy: 0.7526\n",
      "Epoch 20/40\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.3211 - accuracy: 0.8673 - val_loss: 0.6197 - val_accuracy: 0.7423\n",
      "Epoch 21/40\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.3369 - accuracy: 0.8628 - val_loss: 0.4857 - val_accuracy: 0.7423\n",
      "Epoch 22/40\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.3195 - accuracy: 0.8540 - val_loss: 0.4784 - val_accuracy: 0.7423\n",
      "Epoch 23/40\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.3080 - accuracy: 0.8673 - val_loss: 0.5017 - val_accuracy: 0.7423\n",
      "Epoch 24/40\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.3141 - accuracy: 0.8628 - val_loss: 0.4456 - val_accuracy: 0.7629\n",
      "Epoch 25/40\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.3047 - accuracy: 0.8562 - val_loss: 0.5470 - val_accuracy: 0.7423\n",
      "Epoch 26/40\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.3174 - accuracy: 0.8673 - val_loss: 0.4753 - val_accuracy: 0.7526\n",
      "Epoch 27/40\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.3143 - accuracy: 0.8628 - val_loss: 0.5419 - val_accuracy: 0.7423\n",
      "Epoch 28/40\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.2954 - accuracy: 0.8673 - val_loss: 0.4430 - val_accuracy: 0.7526\n",
      "Epoch 29/40\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.3221 - accuracy: 0.8562 - val_loss: 0.4732 - val_accuracy: 0.7423\n",
      "Epoch 30/40\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.3310 - accuracy: 0.8673 - val_loss: 0.4375 - val_accuracy: 0.7629\n",
      "Epoch 31/40\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.3018 - accuracy: 0.8628 - val_loss: 0.4614 - val_accuracy: 0.7526\n",
      "Epoch 32/40\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.3115 - accuracy: 0.8761 - val_loss: 0.5772 - val_accuracy: 0.7423\n",
      "Epoch 33/40\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.2961 - accuracy: 0.8695 - val_loss: 0.4546 - val_accuracy: 0.7629\n",
      "Epoch 34/40\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.2957 - accuracy: 0.8606 - val_loss: 0.4496 - val_accuracy: 0.7835\n",
      "Epoch 35/40\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.3080 - accuracy: 0.8606 - val_loss: 0.5563 - val_accuracy: 0.7423\n",
      "Epoch 36/40\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.3145 - accuracy: 0.8827 - val_loss: 0.5949 - val_accuracy: 0.7423\n",
      "Epoch 37/40\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.3181 - accuracy: 0.8584 - val_loss: 0.4425 - val_accuracy: 0.7835\n",
      "Epoch 38/40\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.3142 - accuracy: 0.8584 - val_loss: 0.4764 - val_accuracy: 0.7423\n",
      "Epoch 39/40\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.3092 - accuracy: 0.8850 - val_loss: 0.5092 - val_accuracy: 0.7423\n",
      "Epoch 40/40\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.3007 - accuracy: 0.8606 - val_loss: 0.4947 - val_accuracy: 0.7423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5b880c7190>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajustando o modelo:\n",
    "model.fit(train_tfd, epochs=40, validation_data=val_tfd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5P4vEJ3LK42"
   },
   "source": [
    "### Ajuste fino da última camada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "OC8yda7iuBMH"
   },
   "outputs": [],
   "source": [
    "# Vamos baixar a taxa de aprendizado:\n",
    "optimizer  = tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
    "model.compile(optimizer, model_loss, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8o2ME3Gti01",
    "outputId": "b726e639-9fe3-4035-ccc6-e55127feeddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 13s 276ms/step - loss: 0.2898 - accuracy: 0.8584 - val_loss: 0.4930 - val_accuracy: 0.7423\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.2913 - accuracy: 0.8673 - val_loss: 0.4825 - val_accuracy: 0.7423\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.3013 - accuracy: 0.8695 - val_loss: 0.4761 - val_accuracy: 0.7423\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.2905 - accuracy: 0.8673 - val_loss: 0.4882 - val_accuracy: 0.7423\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.2991 - accuracy: 0.8827 - val_loss: 0.4842 - val_accuracy: 0.7423\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.3030 - accuracy: 0.8628 - val_loss: 0.4805 - val_accuracy: 0.7423\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.3013 - accuracy: 0.8606 - val_loss: 0.4812 - val_accuracy: 0.7423\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.2883 - accuracy: 0.8650 - val_loss: 0.4930 - val_accuracy: 0.7423\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.2978 - accuracy: 0.8673 - val_loss: 0.4913 - val_accuracy: 0.7423\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.2984 - accuracy: 0.8673 - val_loss: 0.4906 - val_accuracy: 0.7423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5b9c197280>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajustando o modelo:\n",
    "model.fit(train_tfd, epochs=10, validation_data=val_tfd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFTaUoAjLRDq"
   },
   "source": [
    "### Liberar o modelo todo para treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NO5uvF_kLpmt"
   },
   "source": [
    "Agora é importante ir acompanhando a evolução da função de custo tanto para a amostra de treinamento quanto para a amostra de validação. \n",
    "\n",
    "* Uma boa taxa de aprendizado deve levar a uma queda gradual da função de custo na amostra de treinamento. Para não bagunçar os pesos, vamos baixar bastante a taxa de aprendizado.\n",
    "\n",
    "* Quando a função de custo parar de baixar para a amostra de validação, entramos no regime de overfitting. É preciso parar o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VM8by-dpfVYV",
    "outputId": "e97fc9b9-850d-44c7-ee6d-80e21fee713e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108923136 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  769       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,923,905\n",
      "Trainable params: 108,923,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Preparando o modelo com o BERT livre p/ ajustes (vamos baixar ainda mais a taxa de aprendizado):\n",
    "optimizer  = tf.keras.optimizers.Adam(learning_rate=5e-7)\n",
    "model.get_layer('bert').trainable = True\n",
    "model.compile(optimizer, model_loss, metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8_jnIqifjOD",
    "outputId": "c36acde9-1c87-4524-afcc-03885b74c97d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "15/15 [==============================] - 18s 414ms/step - loss: 0.3102 - accuracy: 0.8628 - val_loss: 0.4801 - val_accuracy: 0.7423\n",
      "Epoch 2/40\n",
      "15/15 [==============================] - 3s 220ms/step - loss: 0.2840 - accuracy: 0.8717 - val_loss: 0.4948 - val_accuracy: 0.7423\n",
      "Epoch 3/40\n",
      "15/15 [==============================] - 3s 221ms/step - loss: 0.3097 - accuracy: 0.8717 - val_loss: 0.4949 - val_accuracy: 0.7423\n",
      "Epoch 4/40\n",
      "15/15 [==============================] - 3s 219ms/step - loss: 0.2823 - accuracy: 0.8805 - val_loss: 0.5006 - val_accuracy: 0.7423\n",
      "Epoch 5/40\n",
      "15/15 [==============================] - 3s 219ms/step - loss: 0.2843 - accuracy: 0.8673 - val_loss: 0.4817 - val_accuracy: 0.7423\n",
      "Epoch 6/40\n",
      "15/15 [==============================] - 3s 232ms/step - loss: 0.2665 - accuracy: 0.8850 - val_loss: 0.4735 - val_accuracy: 0.7423\n",
      "Epoch 7/40\n",
      "15/15 [==============================] - 3s 222ms/step - loss: 0.2826 - accuracy: 0.8783 - val_loss: 0.4805 - val_accuracy: 0.7423\n",
      "Epoch 8/40\n",
      "15/15 [==============================] - 3s 220ms/step - loss: 0.2497 - accuracy: 0.8894 - val_loss: 0.4987 - val_accuracy: 0.7423\n",
      "Epoch 9/40\n",
      "15/15 [==============================] - 3s 222ms/step - loss: 0.2641 - accuracy: 0.8673 - val_loss: 0.5003 - val_accuracy: 0.7423\n",
      "Epoch 10/40\n",
      "15/15 [==============================] - 3s 222ms/step - loss: 0.2599 - accuracy: 0.8783 - val_loss: 0.4791 - val_accuracy: 0.7526\n",
      "Epoch 11/40\n",
      "15/15 [==============================] - 3s 233ms/step - loss: 0.2486 - accuracy: 0.8894 - val_loss: 0.4620 - val_accuracy: 0.7629\n",
      "Epoch 12/40\n",
      "15/15 [==============================] - 3s 222ms/step - loss: 0.2670 - accuracy: 0.8783 - val_loss: 0.4675 - val_accuracy: 0.7629\n",
      "Epoch 13/40\n",
      "15/15 [==============================] - 3s 233ms/step - loss: 0.2439 - accuracy: 0.8872 - val_loss: 0.4544 - val_accuracy: 0.7835\n",
      "Epoch 14/40\n",
      "15/15 [==============================] - 3s 223ms/step - loss: 0.2447 - accuracy: 0.8783 - val_loss: 0.4768 - val_accuracy: 0.7629\n",
      "Epoch 15/40\n",
      "15/15 [==============================] - 3s 224ms/step - loss: 0.2386 - accuracy: 0.8982 - val_loss: 0.4889 - val_accuracy: 0.7526\n",
      "Epoch 16/40\n",
      "15/15 [==============================] - 3s 223ms/step - loss: 0.2403 - accuracy: 0.8960 - val_loss: 0.4711 - val_accuracy: 0.7835\n",
      "Epoch 17/40\n",
      "15/15 [==============================] - 3s 221ms/step - loss: 0.2286 - accuracy: 0.8916 - val_loss: 0.4793 - val_accuracy: 0.7732\n",
      "Epoch 18/40\n",
      "15/15 [==============================] - 3s 224ms/step - loss: 0.2352 - accuracy: 0.8982 - val_loss: 0.4708 - val_accuracy: 0.7835\n",
      "Epoch 19/40\n",
      "15/15 [==============================] - 3s 222ms/step - loss: 0.2152 - accuracy: 0.9004 - val_loss: 0.4676 - val_accuracy: 0.7835\n",
      "Epoch 20/40\n",
      "15/15 [==============================] - 3s 222ms/step - loss: 0.2070 - accuracy: 0.9049 - val_loss: 0.4792 - val_accuracy: 0.7732\n",
      "Epoch 21/40\n",
      "15/15 [==============================] - 3s 222ms/step - loss: 0.2104 - accuracy: 0.9027 - val_loss: 0.4744 - val_accuracy: 0.7835\n",
      "Epoch 22/40\n",
      "15/15 [==============================] - 3s 223ms/step - loss: 0.2075 - accuracy: 0.9027 - val_loss: 0.4644 - val_accuracy: 0.7835\n",
      "Epoch 23/40\n",
      "15/15 [==============================] - 3s 235ms/step - loss: 0.2084 - accuracy: 0.9093 - val_loss: 0.4720 - val_accuracy: 0.7835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5b8806e7f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajustando o modelo:\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping('val_loss', patience=10, restore_best_weights=True)\n",
    "model.fit(train_tfd, epochs=40, validation_data=val_tfd, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "RgOnPTYo4OfW"
   },
   "outputs": [],
   "source": [
    "# Salva o modelo treinado:\n",
    "#model.save_pretrained('bertimbau-hatespeech-trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5Spy4eo9Rn_"
   },
   "source": [
    "## Testando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "QiBvQrUvFOSx"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "trg4qwKdgD8U",
    "outputId": "a786d823-1357-489e-eddc-f02fb671f468"
   },
   "outputs": [],
   "source": [
    "#saved_model = TFAutoModelForSequenceClassification.from_pretrained('bertimbau-hatespeech-trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Z9LnEukgtjG",
    "outputId": "26b797b1-4612-4d1e-f63b-837d6880c791"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 77ms/step\n",
      "acc: 0.835\n",
      "f1: 0.529\n",
      "prec: 1.000\n",
      "rec: 0.360\n"
     ]
    }
   ],
   "source": [
    "# Predictions for validation set:\n",
    "val_pred  = predict_class(saved_model, val_tfd)\n",
    "\n",
    "# Metrics:\n",
    "y_true, y_pred = val_df['not_the_target'], val_pred\n",
    "for name, scorer in {'acc': accuracy_score, 'f1': f1_score, 'prec': precision_score, 'rec': recall_score}.items():\n",
    "    s = scorer(y_true, y_pred)\n",
    "    print('{}: {:.3f}'.format(name, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AwspzRwmFbVX",
    "outputId": "e33454c9-a0d7-46dd-e313-9b42a9165f95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 78ms/step\n",
      "acc: 0.825\n",
      "f1: 0.105\n",
      "prec: 0.250\n",
      "rec: 0.067\n"
     ]
    }
   ],
   "source": [
    "# Predictions for test set:\n",
    "test_pred = predict_class(model, test_tfd)\n",
    "\n",
    "# Metrics:\n",
    "y_true, y_pred = test_df['not_the_target'], test_pred\n",
    "for name, scorer in {'acc': accuracy_score, 'f1': f1_score, 'prec': precision_score, 'rec': recall_score}.items():\n",
    "    s = scorer(y_true, y_pred)\n",
    "    print('{}: {:.3f}'.format(name, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "modelo_bert_com_tensorflow.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a3754eebd83498eaf19c4dbd836d6fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11b3d04dc0f3446d8b7d007aaa923865": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_204739ce239b47cb86643f556939e81f",
      "placeholder": "​",
      "style": "IPY_MODEL_0a3754eebd83498eaf19c4dbd836d6fb",
      "value": " 1/1 [00:00&lt;00:00,  4.78ba/s]"
     }
    },
    "204739ce239b47cb86643f556939e81f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28ac59e6f3ad4442837e470d63a5913a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28f9d87645184fca8b8305167b4c2539": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f51f1a3231d4b4eb20b407b5664f78f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b6ca3c2ac2c4f4c88c9528f52f075a3",
      "placeholder": "​",
      "style": "IPY_MODEL_707bd0c951ff46d88df758e3dfc7faec",
      "value": "100%"
     }
    },
    "3fba13def095450f9c9b2dd0c65f5fd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4e62dbd2382d4d15aa49cff8de61be53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "585fa61fe96b4c11bf0163b3ea646cd2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6250c40f8e114db9a226db01ce2a1d84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bae291373ce24ce1a0594334ae2ce414",
       "IPY_MODEL_734e8736e4b948c790536a524aaf7f01",
       "IPY_MODEL_9d91c870729c4cfba700acda20eeef0d"
      ],
      "layout": "IPY_MODEL_4e62dbd2382d4d15aa49cff8de61be53"
     }
    },
    "707bd0c951ff46d88df758e3dfc7faec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "734e8736e4b948c790536a524aaf7f01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_585fa61fe96b4c11bf0163b3ea646cd2",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_976513a8ec674d3fb16cb04d8166533a",
      "value": 5
     }
    },
    "7f0a57db827b4b47a492759ac218377d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b6ca3c2ac2c4f4c88c9528f52f075a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "976513a8ec674d3fb16cb04d8166533a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d91c870729c4cfba700acda20eeef0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bfe43e79dae34624bad82ab5cab0e4bf",
      "placeholder": "​",
      "style": "IPY_MODEL_28f9d87645184fca8b8305167b4c2539",
      "value": " 5/5 [00:00&lt;00:00,  6.03ba/s]"
     }
    },
    "b2ae2782be834feeaffde4e50fc0e3f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bae291373ce24ce1a0594334ae2ce414": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd5d6dfa298b4756a6d4e714cdefedd5",
      "placeholder": "​",
      "style": "IPY_MODEL_b2ae2782be834feeaffde4e50fc0e3f2",
      "value": "100%"
     }
    },
    "bfe43e79dae34624bad82ab5cab0e4bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd5d6dfa298b4756a6d4e714cdefedd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d390ffb74d5044f8b0c847c30191957c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28ac59e6f3ad4442837e470d63a5913a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3fba13def095450f9c9b2dd0c65f5fd0",
      "value": 1
     }
    },
    "dd64a6ae604847808188a63f60b9dd6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3f51f1a3231d4b4eb20b407b5664f78f",
       "IPY_MODEL_d390ffb74d5044f8b0c847c30191957c",
       "IPY_MODEL_11b3d04dc0f3446d8b7d007aaa923865"
      ],
      "layout": "IPY_MODEL_7f0a57db827b4b47a492759ac218377d"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
